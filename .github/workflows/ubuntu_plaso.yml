name: Process Evidence Folders with Plaso and Send to Splunk

on:
  push:
    paths:
      - 'uac/**' # Monitor changes in the uac directory

jobs:
  detect-new-folders:
    runs-on: ubuntu-22.04

    outputs:
      folders: ${{ steps.detect.outputs.folders }}

    steps:
      # Step 1: Checkout the repository with full history
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      # Step 2: Identify new folders
      - name: Identify New Folders
        id: detect
        run: |
          git fetch origin
          FOLDER_PATH="uac"
          NEW_FOLDERS=$(git diff --name-status HEAD^ HEAD \
            | grep "^A" \
            | grep "^A\suac/" \
            | awk '{print $2}' \
            | awk -F/ '{print $2}' \
            | sort -u)

          echo "Newly detected folders:"
          echo "$NEW_FOLDERS"

          if [ -z "$NEW_FOLDERS" ]; then
            FOLDERS_JSON="[]"
          else
            FOLDERS_JSON=$(echo "$NEW_FOLDERS" | jq -R -s -c 'split("\n") | map(select(. != ""))')
          fi

          echo "FOLDERS_JSON=$FOLDERS_JSON"

          # Set the output using GITHUB_OUTPUT
          echo "folders=$FOLDERS_JSON" >> "$GITHUB_OUTPUT"

  process-folder:
    needs: detect-new-folders

    if: needs.detect-new-folders.outputs.folders != '[]'

    runs-on: ubuntu-22.04

    strategy:
      matrix:
        folder: ${{ fromJson(needs.detect-new-folders.outputs.folders) }}

    steps:
      # Step 1: Checkout the repository
      - name: Checkout Repository
        uses: actions/checkout@v3

      # Step 2: Install Python and Dependencies
      - name: Install Plaso Tools and Python Dependencies
        run: |
          sudo apt update
          sudo apt install -y python3-plaso python3-pip
          pip3 install requests

      # Step 3: Extract tar.gz files (if present)
      - name: Extract tar.gz Files
        run: |
          echo "Checking for tar.gz files in ./uac/${{ matrix.folder }}"
          if ls ./uac/${{ matrix.folder }}/*.tar.gz 1> /dev/null 2>&1; then
            for archive in ./uac/${{ matrix.folder }}/*.tar.gz; do
              echo "Extracting $archive"
              tar -xzf "$archive" -C "./uac/${{ matrix.folder }}"
            done
          else
            echo "No tar.gz files found in ./uac/${{ matrix.folder }}"
          fi

      # Step 4: Run psteal.py on the assigned folder
      - name: Process Evidence with psteal
        run: |
          echo "Processing folder: ./uac/${{ matrix.folder }}"
          psteal.py \
            --source "./uac/${{ matrix.folder }}/" \
            -w "./inv-${{ matrix.folder }}.json" \
            -o json_line

      # Step 5: Send JSON output to Splunk
      - name: Send to Splunk
        env:
          SPLUNK_URL: 'https://http-inputs-remitly.splunkcloud.com/services/collector/event'
          SPLUNK_TOKEN: 'b8eb4e10-6ea8-4c26-a296-0dfd96c401c7'
        run: |
          echo "Sending inv-${{ matrix.folder }}.json to Splunk"
          python3 - <<EOF
import json
import requests

def send_to_splunk_event(json_file_path, splunk_url, splunk_token):
    try:
        # Read the JSON file
        with open(json_file_path, 'r') as file:
            json_str = file.read()

        # Parse the JSON event
        data = json.loads(json_str)

        # Wrap the JSON object inside 'event'
        payload = {"event": data}

        # Convert the payload to string
        payload_str = json.dumps(payload)

        # Set headers for the HTTP request
        headers = {
            'Authorization': f'Splunk {splunk_token}',
            'Content-Type': 'application/json'
        }

        # Send the data to Splunk
        response = requests.post(splunk_url, headers=headers, data=payload_str)

        # Check the response from Splunk
        if response.status_code != 200:
            print(f"Failed to send data to Splunk. Status code: {response.status_code}")
            print(response.text)
        else:
            print("Successfully sent data to Splunk.")

    except json.JSONDecodeError as e:
        print(f"Error decoding JSON: {e}")
    except Exception as e:
        print(f"Error: {e}")

# Call the function with environment variables and JSON file path
send_to_splunk_event(
    json_file_path=f"./inv-${{ matrix.folder }}.json",
    splunk_url="${{ env.SPLUNK_URL }}",
    splunk_token="${{ env.SPLUNK_TOKEN }}"
)
EOF

      # Step 6: Upload the JSON file as an artifact (for backup)
      - name: Upload JSON Output
        uses: actions/upload-artifact@v3
        with:
          name: "inv-${{ matrix.folder }}"
          path: "./inv-${{ matrix.folder }}.json"
